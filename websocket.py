import asyncio
import logging
import json
import websockets
import pandas as pd
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
import aiohttp
from urllib.parse import urlencode

from globals import BINANCE_WS_URL, TRADING_PAIRS, TIMEFRAMES, SAFETY_LIMITS

logger = logging.getLogger(__name__)

class BinanceWebSocket:
    def __init__(self):
        self.ws_url = BINANCE_WS_URL
        self.pairs = TRADING_PAIRS
        self.timeframes = TIMEFRAMES
        self.connections = {}
        self.market_data = {}
        self.is_running = False
        
        # Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñ‹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
        self._initialize_market_data()
        
    def _initialize_market_data(self):
        """Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñ‹ Ñ€Ñ‹Ğ½Ğ¾Ñ‡Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…"""
        for pair in self.pairs:
            self.market_data[pair] = {}
            for timeframe in self.timeframes:
                self.market_data[pair][timeframe] = pd.DataFrame(columns=[
                    'timestamp', 'open', 'high', 'low', 'close', 'volume'
                ])
                
    async def initialize(self):
        """Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ WebSocket ÑĞ¾ĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ğ¹"""
        try:
            logger.info("ğŸ”Œ Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Binance WebSocket...")
            
            # ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
            await self._fetch_historical_data()
            
            # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ WebSocket ÑĞ¾ĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ğ¹
            await self._create_websocket_connections()
            
            logger.info("âœ… Binance WebSocket Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½")
            
        except Exception as e:
            logger.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ WebSocket: {e}")
            raise
            
    async def _fetch_historical_data(self):
        """ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ñ‡ĞµÑ€ĞµĞ· REST API"""
        try:
            logger.info("ğŸ“Š Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° ÑĞ¸Ğ¼ÑƒĞ»ÑÑ†Ğ¸Ğ¸ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…...")
            
            # Ğ¡Ğ¸Ğ¼ÑƒĞ»ÑÑ†Ğ¸Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ğ¸
            await self._generate_simulated_data()
            
            logger.info("âœ… Ğ¡Ğ¸Ğ¼ÑƒĞ»ÑÑ†Ğ¸Ñ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ°")
            
        except Exception as e:
            logger.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…: {e}")
            raise
            
    async def _generate_simulated_data(self):
        """Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ ÑĞ¸Ğ¼ÑƒĞ»ÑÑ†Ğ¸Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ"""
        try:
            import random
            import numpy as np
            
            for pair in self.pairs:
                base_price = {
                    'BTCUSDT': 65000,
                    'ETHUSDT': 3500,
                    'BNBUSDT': 600,
                    'ADAUSDT': 0.45,
                    'XRPUSDT': 0.60,
                    'SOLUSDT': 150,
                    'DOGEUSDT': 0.25
                }.get(pair, 100)
                
                for timeframe in self.timeframes:
                    # Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ 500 Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… ÑĞ²ĞµÑ‡ĞµĞ¹
                    df_data = []
                    current_time = datetime.now()
                    
                    # ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ²Ğ°Ğ»Ğ° Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸
                    time_delta = {
                        '1m': timedelta(minutes=1),
                        '5m': timedelta(minutes=5),
                        '15m': timedelta(minutes=15),
                        '30m': timedelta(minutes=30),
                        '1h': timedelta(hours=1),
                        '4h': timedelta(hours=4),
                        '1d': timedelta(days=1)
                    }.get(timeframe, timedelta(minutes=1))
                    
                    price = base_price
                    
                    for i in range(500):
                        # Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ ÑĞ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ğ¾Ğ³Ğ¾ Ğ´Ğ²Ğ¸Ğ¶ĞµĞ½Ğ¸Ñ Ñ†ĞµĞ½Ñ‹
                        price_change = random.uniform(-0.05, 0.05)  # Â±5%
                        price = price * (1 + price_change)
                        
                        # Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ OHLC Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
                        open_price = price
                        high_price = price * (1 + abs(random.uniform(0, 0.02)))
                        low_price = price * (1 - abs(random.uniform(0, 0.02)))
                        close_price = price * (1 + random.uniform(-0.01, 0.01))
                        volume = random.uniform(1000, 10000)
                        
                        candle_time = current_time - (time_delta * (500 - i))
                        
                        df_data.append({
                            'timestamp': candle_time,
                            'open': open_price,
                            'high': high_price,
                            'low': low_price,
                            'close': close_price,
                            'volume': volume
                        })
                        
                        price = close_price
                        
                    self.market_data[pair][timeframe] = pd.DataFrame(df_data)
                    logger.debug(f"ğŸ“ˆ Ğ¡Ğ¸Ğ¼ÑƒĞ»ÑÑ†Ğ¸Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ°: {pair} {timeframe} - {len(df_data)} ÑĞ²ĞµÑ‡ĞµĞ¹")
                    
        except Exception as e:
            logger.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ ÑĞ¸Ğ¼ÑƒĞ»ÑÑ†Ğ¸Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…: {e}")
            raise
            
    async def _fetch_pair_timeframe_data(self, session: aiohttp.ClientSession, base_url: str, pair: str, timeframe: str):
        """ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ğ¾Ğ¹ Ğ¿Ğ°Ñ€Ñ‹ Ğ¸ Ñ‚Ğ°Ğ¹Ğ¼Ñ„Ñ€ĞµĞ¹Ğ¼Ğ°"""
        try:
            # ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ°
            params = {
                'symbol': pair,
                'interval': timeframe,
                'limit': 500
            }
            
            url = f"{base_url}?{urlencode(params)}"
            
            async with session.get(url) as response:
                if response.status == 200:
                    data = await response.json()
                    
                    df_data = []
                    for candle in data:
                        df_data.append({
                            'timestamp': pd.to_datetime(candle[0], unit='ms'),
                            'open': float(candle[1]),
                            'high': float(candle[2]),
                            'low': float(candle[3]),
                            'close': float(candle[4]),
                            'volume': float(candle[5])
                        })
                        
                    self.market_data[pair][timeframe] = pd.DataFrame(df_data)
                    
                    logger.debug(f"ğŸ“ˆ Ğ”Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ñ‹: {pair} {timeframe} - {len(df_data)} ÑĞ²ĞµÑ‡ĞµĞ¹")
                    
                else:
                    logger.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… {pair} {timeframe}: {response.status}")
                    
        except Exception as e:
            logger.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… {pair} {timeframe}: {e}")
            
    async def _create_websocket_connections(self):
        """Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ WebSocket ÑĞ¾ĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ğ¹ - ÑĞ¸Ğ¼ÑƒĞ»ÑÑ†Ğ¸Ñ"""
        try:
            logger.info("ğŸ”Œ Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ ÑĞ¸Ğ¼ÑƒĞ»ÑÑ†Ğ¸Ğ¸ WebSocket ÑĞ¾ĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ğ¹...")
            
            # Ğ¡Ğ¸Ğ¼ÑƒĞ»ÑÑ†Ğ¸Ñ ÑĞ¾ĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ñ
            self.connections['main'] = 'simulated_connection'
            
            logger.info("âœ… Ğ¡Ğ¸Ğ¼ÑƒĞ»ÑÑ†Ğ¸Ñ WebSocket ÑĞ¾ĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ğ¹ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ°")
            
        except Exception as e:
            logger.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ WebSocket ÑĞ¾ĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ğ¹: {e}")
            raise
            
    async def start_data_stream(self):
        """Ğ—Ğ°Ğ¿ÑƒÑĞº Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… - ÑĞ¸Ğ¼ÑƒĞ»ÑÑ†Ğ¸Ñ"""
        try:
            if self.is_running:
                return
                
            self.is_running = True
            logger.info("ğŸš€ Ğ—Ğ°Ğ¿ÑƒÑĞº ÑĞ¸Ğ¼ÑƒĞ»ÑÑ†Ğ¸Ğ¸ Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…...")
            
            # Ğ—Ğ°Ğ¿ÑƒÑĞº ÑĞ¸Ğ¼ÑƒĞ»ÑÑ†Ğ¸Ğ¸ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
            await self._simulate_data_updates()
            
        except Exception as e:
            logger.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ·Ğ°Ğ¿ÑƒÑĞºĞ° Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…: {e}")
            raise
        finally:
            self.is_running = False
            
    async def _simulate_data_updates(self):
        try:
            import random
            
            while self.is_running:
                # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¹ Ğ¿Ğ°Ñ€Ñ‹
                for pair in self.pairs:
                    for timeframe in self.timeframes:
                        if pair in self.market_data and timeframe in self.market_data[pair]:
                            df = self.market_data[pair][timeframe]
                            
                            if len(df) > 0:
                                # ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ĞµĞ¹ ÑĞ²ĞµÑ‡Ğ¸
                                last_candle = df.iloc[-1].copy()
                                
                                # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ñ†ĞµĞ½Ñ‹ Ñ Ğ½ĞµĞ±Ğ¾Ğ»ÑŒÑˆĞ¸Ğ¼ ÑĞ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ñ‹Ğ¼ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸ĞµĞ¼
                                price_change = random.uniform(-0.001, 0.001)  # Â±0.1%
                                new_close = last_candle['close'] * (1 + price_change)
                                
                                # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ĞµĞ¹ ÑĞ²ĞµÑ‡Ğ¸
                                df.iloc[-1, df.columns.get_loc('close')] = new_close
                                df.iloc[-1, df.columns.get_loc('high')] = max(last_candle['high'], new_close)
                                df.iloc[-1, df.columns.get_loc('low')] = min(last_candle['low'], new_close)
                                df.iloc[-1, df.columns.get_loc('volume')] = last_candle['volume'] + random.uniform(10, 100)
                                
                                logger.debug(f"ğŸ“Š Ğ¡Ğ¸Ğ¼ÑƒĞ»ÑÑ†Ğ¸Ñ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ: {pair} {timeframe} - {new_close:.4f}")
                
                # ĞŸĞ°ÑƒĞ·Ğ° Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸ÑĞ¼Ğ¸
                await asyncio.sleep(1)
                
        except Exception as e:
            logger.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° ÑĞ¸Ğ¼ÑƒĞ»ÑÑ†Ğ¸Ğ¸ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…: {e}")
            self.is_running = False
            
    def get_market_data(self) -> Dict[str, Dict[str, pd.DataFrame]]:
        """ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ€Ñ‹Ğ½Ğ¾Ñ‡Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…"""
        return self.market_data.copy()
        
    def get_latest_price(self, pair: str) -> Optional[float]:
        """ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ĞµĞ¹ Ñ†ĞµĞ½Ñ‹ Ğ´Ğ»Ñ Ğ¿Ğ°Ñ€Ñ‹"""
        try:
            if pair in self.market_data and '1m' in self.market_data[pair]:
                df = self.market_data[pair]['1m']
                if len(df) > 0:
                    return df['close'].iloc[-1]
            return None
            
        except Exception as e:
            logger.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ†ĞµĞ½Ñ‹ Ğ´Ğ»Ñ {pair}: {e}")
            return None
            
    def get_pair_timeframe_data(self, pair: str, timeframe: str) -> Optional[pd.DataFrame]:
        """ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ğ¾Ğ¹ Ğ¿Ğ°Ñ€Ñ‹ Ğ¸ Ñ‚Ğ°Ğ¹Ğ¼Ñ„Ñ€ĞµĞ¹Ğ¼Ğ°"""
        try:
            if pair in self.market_data and timeframe in self.market_data[pair]:
                return self.market_data[pair][timeframe].copy()
            return None
            
        except Exception as e:
            logger.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… {pair} {timeframe}: {e}")
            return None
            
    async def shutdown(self):
        """Ğ—Ğ°ĞºÑ€Ñ‹Ñ‚Ğ¸Ğµ Ğ²ÑĞµÑ… ÑĞ¾ĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ğ¹"""
        try:
            logger.info("ğŸ›‘ Ğ—Ğ°ĞºÑ€Ñ‹Ñ‚Ğ¸Ğµ WebSocket ÑĞ¾ĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ğ¹...")
            
            self.is_running = False
            
            # Ğ—Ğ°ĞºÑ€Ñ‹Ñ‚Ğ¸Ğµ Ğ²ÑĞµÑ… ÑĞ¾ĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ğ¹
            for conn_name, connection in self.connections.items():
                try:
                    if hasattr(connection, "close") and callable(connection.close):
                        await connection.close()
                        logger.info(f"âœ… Ğ¡Ğ¾ĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ğµ {conn_name} Ğ·Ğ°ĞºÑ€Ñ‹Ñ‚Ğ¾")
                except Exception as e:
                    logger.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ·Ğ°ĞºÑ€Ñ‹Ñ‚Ğ¸Ñ ÑĞ¾ĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ñ {conn_name}: {e}")
                    
            self.connections.clear()
            
            logger.info("âœ… Ğ’ÑĞµ WebSocket ÑĞ¾ĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ñ Ğ·Ğ°ĞºÑ€Ñ‹Ñ‚Ñ‹")
            
        except Exception as e:
            logger.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ·Ğ°ĞºÑ€Ñ‹Ñ‚Ğ¸Ñ ÑĞ¾ĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ğ¹: {e}")
            
    def get_connection_status(self) -> Dict[str, Any]:
        """ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ ÑÑ‚Ğ°Ñ‚ÑƒÑĞ° ÑĞ¾ĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ğ¹"""
        return {
            'is_running': self.is_running,
            'connections_count': len(self.connections),
            'pairs_count': len(self.pairs),
            'timeframes_count': len(self.timeframes),
            'total_streams': len(self.pairs) * len(self.timeframes)
        }
        
    def get_data_statistics(self) -> Dict[str, Any]:
        """ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…"""
        stats = {
            'total_pairs': len(self.pairs),
            'total_timeframes': len(self.timeframes),
            'data_points': {},
            'latest_updates': {}
        }
        
        for pair in self.pairs:
            stats['data_points'][pair] = {}
            stats['latest_updates'][pair] = {}
            
            for timeframe in self.timeframes:
                df = self.market_data[pair][timeframe]
                stats['data_points'][pair][timeframe] = len(df)
                
                if len(df) > 0:
                    stats['latest_updates'][pair][timeframe] = df['timestamp'].iloc[-1].isoformat()
                else:
                    stats['latest_updates'][pair][timeframe] = None
                    
        return stats
      
